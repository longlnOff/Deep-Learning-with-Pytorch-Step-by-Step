{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Rethinking the Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_step(model, loss_fn, optimizer):\n",
    "    # Builds function that performs a step in the train loop\n",
    "    def perform_train_step(x, y):\n",
    "        # Set model to TRAIN mode\n",
    "        model.train()\n",
    "\n",
    "        # Compute prediction and loss\n",
    "        yhat = model(x)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(yhat, y)\n",
    "        \n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Return the loss\n",
    "        return loss.item()\n",
    "    \n",
    "    # Return the function that will be called inside the train loop\n",
    "    return perform_train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../data_preparation/v0.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../model_configuration/v1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../model_configuration/v1.py\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set learning rate\n",
    "lr = 0.001\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create model and send it to device\n",
    "model = torch.nn.Sequential(torch.nn.Linear(1, 1)).to(device)\n",
    "\n",
    "# Defines a optimizer to update the parameters of the model\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Define the MSE loss function\n",
    "loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Create the train_step function for our model, loss function and optimizer\n",
    "train_step = make_train_step(model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../model_configuration/v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../model_training/v1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../model_training/v1.py\n",
    "\n",
    "# Define number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "losses = [] \n",
    "\n",
    "# For each epoch ...\n",
    "for epoch in range(n_epochs):\n",
    "    # Perform one train step and record the corresponding loss\n",
    "    loss = train_step(x_train_tensor, y_train_tensor)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../model_training/v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[1.1880]], device='cuda:0')),\n",
       "             ('0.bias', tensor([1.3553], device='cuda:0'))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(losses)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.7713]), tensor([2.4745]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "x_train_tensor = torch.as_tensor(x_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.as_tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "train_data = CustomDataset(x_train_tensor, y_train_tensor)\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4722],\n",
       "         [0.9696],\n",
       "         [0.1220],\n",
       "         [0.7751],\n",
       "         [0.8022],\n",
       "         [0.7296],\n",
       "         [0.0977],\n",
       "         [0.1849]]),\n",
       " tensor([[1.9857],\n",
       "         [2.8401],\n",
       "         [1.2406],\n",
       "         [2.4936],\n",
       "         [2.6229],\n",
       "         [2.5751],\n",
       "         [1.4417],\n",
       "         [1.5888]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[8:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../data_preparation/v1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../data_preparation/v1.py\n",
    "\n",
    "# our data was in Numpy arrays, but we need to transform them into PyTorch tensors\n",
    "x_train_tensor = torch.as_tensor(x_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.as_tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "# Builds Dataset\n",
    "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "\n",
    "# Builds DataLoader\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=16,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../data_preparation/v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../model_configuration/v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../model_training/v2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../model_training/v2.py\n",
    "\n",
    "# Incorporate the mini-batch gradient descent logic into our model training part of the code\n",
    "# Define number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "losses = []\n",
    "\n",
    "# For each epoch ...\n",
    "for epoch in range(n_epochs):\n",
    "    # Inner loop: for each mini-batch\n",
    "    mini_batch_losses = []\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # The dataset 'lives' in the CPu, so do our mini-batches\n",
    "        # therefore, we need to send them to the device where the model lives\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        # Perform one train step and record the corresponding loss\n",
    "        loss_mini_batch = train_step(x_batch, y_batch)\n",
    "        mini_batch_losses.append(loss_mini_batch)\n",
    "\n",
    "    # Compute the average loss for the epoch\n",
    "    loss = np.mean(mini_batch_losses)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../model_training/v2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.5572]], device='cuda:0')), ('0.bias', tensor([1.2340], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.5572]], device='cuda:0')), ('0.bias', tensor([1.2340], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "%run -i ../data_preparation/v1.py\n",
    "%run -i ../model_configuration/v1.py\n",
    "%run -i ../model_training/v2.py\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def mini_batch(device, data_loader, step):\n",
    "    mini_batch_losses = []\n",
    "    for x_batch, y_batch in data_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        mini_batch_loss = step(x_batch, y_batch)\n",
    "        mini_batch_losses.append(mini_batch_loss)\n",
    "    \n",
    "    return np.mean(mini_batch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../model_training/v3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../model_training/v3.py\n",
    "\n",
    "\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 200\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # inner loop\n",
    "    loss = mini_batch(device, train_loader, train_step)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../model_training/v3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.6149]], device='cuda:0')), ('0.bias', tensor([1.2045], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../data_preparation/v2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../data_preparation/v2.py\n",
    "\n",
    "torch.manual_seed(13)\n",
    "\n",
    "# Builds tensors from numpy array BEFORE split\n",
    "x_tensor = torch.as_tensor(x, dtype=torch.float32)\n",
    "y_tensor = torch.as_tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Builds Dataset containing all the data points\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "\n",
    "# Performs the split\n",
    "ratio = 0.8\n",
    "n_total = len(dataset)\n",
    "n_train = int(ratio * n_total)\n",
    "n_val = n_total - n_train\n",
    "\n",
    "train_data, val_data = random_split(dataset, [n_train, n_val])\n",
    "\n",
    "# Builds DataLoader\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../data_preparation/v2.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_val_step(model, loss_fn):\n",
    "    # Builds function that performs a validation step in the validation loop\n",
    "    def perform_val_step(x, y):\n",
    "        # Sets model to EVAL mode\n",
    "        model.eval()\n",
    "\n",
    "        # Step 1 - Computes our model's predicted output\n",
    "        # Forward pass\n",
    "        # model_device = model.to(device)\n",
    "        # x = x.to(device)\n",
    "        yhat = model(x)\n",
    "\n",
    "        # Step 2: Computes the loss\n",
    "        loss = loss_fn(yhat, y)\n",
    "\n",
    "        # There is no need to compute Steps 3 and 4,\n",
    "        # since we don't update parameters during evaluation\n",
    "        return loss.item()\n",
    "    \n",
    "    return perform_val_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../model_configuration/v2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../model_configuration/v2.py\n",
    "\n",
    "# Set the learning rate\n",
    "learning_rate = 1e-3\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create model\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1, 1)).to(device)\n",
    "\n",
    "# Define optimizer to update the model's parameters\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Create the train-step function for our model, loss function and optimizer\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "# Create the validation-step function for our model and loss function\n",
    "val_step = make_val_step(model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../model_configuration/v2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../model_training/v4.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../model_training/v4.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 200\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # inner loop\n",
    "    # Training\n",
    "    loss = mini_batch(device, train_loader, train_step)\n",
    "    losses.append(loss)\n",
    "\n",
    "    # Validation - NO GRADIENTS IN VALIDATION\n",
    "    with torch.no_grad():\n",
    "        val_loss = mini_batch(device, val_loader, val_step)\n",
    "        val_losses.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../model_training/v4.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.3462]], device='cuda:0')), ('0.bias', tensor([1.3083], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> #### Plotting Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[1.3462]], device='cuda:0')),\n",
       "             ('0.bias', tensor([1.3083], device='cuda:0'))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run -i ../data_preparation/v2.py\n",
    "%run -i ../model_configuration/v2.py\n",
    "%run -i ../model_training/v4.py\n",
    "model.state_dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 3334127), started 0:25:30 ago. (Use '!kill 3334127' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-74686737c616108f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-74686737c616108f\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 11:17:49.539516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('run/test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> #### add_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching a tuple of feature (dummy_x) and label (dummy_y) from the train_loader\n",
    "dummy_x, dummy_y = next(iter(train_loader))\n",
    "\n",
    "# Since our model was sent to device, we need to do the same with our dummy data\n",
    "# Even here, both model and data need to be on the same device!\n",
    "writer.add_graph(model, dummy_x.to(device))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> #### add_scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_scalars(\n",
    "    main_tag='Loss',\n",
    "    tag_scalar_dict={'training': loss,\n",
    "                        'validation': val_loss},\n",
    "    global_step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../data_preparation/v2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../model_configuration/v3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../model_configuration/v3.py\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set the learning rate\n",
    "learning_rate = 1e-3\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create model\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1, 1)).to(device)\n",
    "\n",
    "# Define optimizer to update the model's parameters\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Create the train-step function for our model, loss function and optimizer\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "# Create the validation-step function for our model and loss function\n",
    "val_step = make_val_step(model, loss_fn)\n",
    "\n",
    "# Creates a SummaryWriter to interface with TensorBoard\n",
    "writer = SummaryWriter('runs/simple_LR')\n",
    "\n",
    "# Fetching a tuple of feature (dummy_x) and label (dummy_y) from the train_loader\n",
    "dummy_x, dummy_y = next(iter(train_loader))\n",
    "writer.add_graph(model, dummy_x.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../model_configuration/v3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../model_training/v5.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../model_training/v5.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 200\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # inner loop\n",
    "    # Training\n",
    "    loss = mini_batch(device, train_loader, train_step)\n",
    "    losses.append(loss)\n",
    "\n",
    "    # Validation - NO GRADIENTS IN VALIDATION\n",
    "    with torch.no_grad():\n",
    "        val_loss = mini_batch(device, val_loader, val_step)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "    # Writes to TensorBoard\n",
    "    writer.add_scalars(\n",
    "        main_tag='Loss',\n",
    "        tag_scalar_dict={'training': loss,\n",
    "                            'validation': val_loss},\n",
    "        global_step=epoch)\n",
    "\n",
    "# close the writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../model_training/v5.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Saving and Loading Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> #### Model State"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> ##### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {  'epoch': n_epochs,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': losses,\n",
    "                'val_loss': val_losses}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint_folder/checkpoint.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> ##### Resuming Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../data_preparation/v2.py\n",
    "%run -i ../model_configuration/v3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[0.7645]], device='cuda:0')),\n",
       "             ('0.bias', tensor([0.8300], device='cuda:0'))])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('checkpoint_folder/checkpoint.pth')\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "losses = checkpoint['loss']\n",
    "val_losses = checkpoint['val_loss']\n",
    "\n",
    "model.train()       # ALWAYS SET TO TRAIN MODE FOR RESUMING TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[1.3466]], device='cuda:0')),\n",
       "             ('0.bias', tensor([1.3081], device='cuda:0'))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[1.5691]], device='cuda:0')),\n",
       "             ('0.bias', tensor([1.2239], device='cuda:0'))])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run -i ../model_training/v5.py\n",
    "model.state_dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> ##### Deploying / Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../model_configuration/v3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[1.3466]], device='cuda:0')),\n",
       "             ('0.bias', tensor([1.3081], device='cuda:0'))])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('checkpoint_folder/checkpoint.pth')\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.0415],\n",
       "        [10.7348],\n",
       "        [ 4.0014]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_input = torch.tensor([[5.0], [7.], [2.]])\n",
    "\n",
    "model.eval()       # ALWAYS SET TO EVAL MODE FOR INFERENCE\n",
    "model(new_input.to(device))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Putting It All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load data_preparation/v2.py\n",
    "torch.manual_seed(13)\n",
    "\n",
    "# Builds tensors from numpy arrays BEFORE splitting\n",
    "x_tensor = torch.as_tensor(x, dtype=torch.float32)\n",
    "y_tensor = torch.as_tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Builds dataset containing ALL data points\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "# Splits dataset into train and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Builds data loaders for train and validation sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load model_configuration/v3.py\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set the learning rate\n",
    "learning_rate = 1e-3\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create model\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1, 1)).to(device)\n",
    "\n",
    "# Define optimizer to update the model's parameters\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Create the train-step function for our model, loss function and optimizer\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "# Create the validation-step function for our model and loss function\n",
    "val_step = make_val_step(model, loss_fn)\n",
    "\n",
    "# Creates a SummaryWriter to interface with TensorBoard\n",
    "writer = SummaryWriter('runs/simple_LR')\n",
    "\n",
    "# Fetching a tuple of feature (dummy_x) and label (dummy_y) from the train_loader\n",
    "dummy_x, dummy_y = next(iter(train_loader))\n",
    "writer.add_graph(model, dummy_x.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load model_training/v5.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 200\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # inner loop\n",
    "    # Training\n",
    "    loss = mini_batch(device, train_loader, train_step)\n",
    "    losses.append(loss)\n",
    "\n",
    "    # Validation - NO GRADIENTS IN VALIDATION\n",
    "    with torch.no_grad():\n",
    "        val_loss = mini_batch(device, val_loader, val_step)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "    # Writes to TensorBoard\n",
    "    writer.add_scalars(\n",
    "        main_tag='Loss',\n",
    "        tag_scalar_dict={'training': loss,\n",
    "                            'validation': val_loss},\n",
    "        global_step=epoch)\n",
    "    \n",
    "# Close the writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[1.2076]], device='cuda:0')),\n",
       "             ('0.bias', tensor([1.2423], device='cuda:0'))])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:01:55) \n[GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1215c5260df236461e170f4e1d0dbd1602766d0efc0ea9c7f4a2d9ba9d1609c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
